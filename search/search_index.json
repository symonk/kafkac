{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#kafkac-a-kafka-consumer-framework-for-python","title":"\ud83d\udc0d kafkac \u2014 A Kafka Consumer framework for python","text":"<p>kafkac is a minimal, opinionated framework for building reliable Kafka consumers in Python using the confluent-kafka client. It abstracts away the boilerplate of manual offset handling, shutdown coordination, and message deserialization - giving you a clean async interface for consuming messages safely and predictably.</p> <p>[!IMPORTANT] kafkac prioritises correctness and speed, in that order, avoiding message loss at all costs.</p> <p>[!CAUTION] Always write your consumer to be idempotent.  Guaranteeing you will never see a duplicate message is not trivial.</p>"},{"location":"#core-features","title":"\u2699\ufe0f Core Features","text":"<ul> <li>\u26a1\ufe0f Fully asynchronous message consumption</li> <li>\ud83e\uddec Version-aware model deserialization (Pydantic)</li> <li>\ud83d\udee1 Handles common Kafka edge cases and failure scenarios</li> <li>\ud83d\udce6 Batch consumption to reduce RTT and executor overhead</li> <li>\ud83e\uddfe Header-level message filtering support with out of the box filters</li> <li>\ud83d\udcca Built-in metrics &amp; OpenTelemetry integration</li> <li>\ud83e\udde9 Pluggable middleware for pre/post-processing</li> <li>\ud83e\udea6 Automatic dead-letter queueing for poison-pill messages</li> <li>\ud83d\udd01 Smart retries with exponential backoff</li> <li>\ud83e\uddd8 Automatic rebalance management</li> <li>\u2728 And more...</li> </ul>"},{"location":"#benchmarks","title":"Benchmarks","text":"<p>Below are some benchmarks that preload various levels of messages onto a topic, run a <code>kafkac</code> consumer to process those messages, writing the messages to another topic, confirming all the messages are accounted for.</p> <p>// TODO</p>"},{"location":"#quick-start","title":"\ud83e\udde0 Quick Start","text":"<pre><code>import asyncio\n\nfrom kafkac import AsyncKafkaConsumer\nfrom kafkac import PartitionResult\nfrom confluent_kafka import Message\n\n\nasync def handler(messages: list[Message]) -&gt; PartitionResult:\n    return PartitionResult(succeeded=messages)\n\n\nasync def main():\n    config = {\n        \"group.id\": \"foo\",\n        \"bootstrap.servers\": \"localhost:9092\",\n    },\n    async with AsyncKafkaConsumer(\n            handler_func=handler,\n            config=config,\n            topic_regexes=[\"^topic$\"],\n            batch_size=1000,\n    ) as consumer:\n        await asyncio.sleep(60)\n        await consumer.stop()\n        # context manager will exit cleanly once the consumer has finalised.\n        # last messages will be processed and handled before graceful exit.\n\n\nif __name__ == \"__main__\":\n    asyncio.gather(main())\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>The project uses <code>testcontainers</code> to run an actual <code>kafka</code> container throughout integration tests to ensure it is tested against something that at least resembles the real world.  In order for this to function, ensure the <code>docker</code> service is running.</p>"}]}